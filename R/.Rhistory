## Empty objects to store results
slope_folds <- c()
intercept_folds <- c()
R2_folds <- c()
eci_folds <- c()
# For each fold, calculate calibration intercept & slope, R2 and ECI
for (v in 1:V){
# for easy reference
data <- df[unlist(foldsb[[v]]),]
ppf <- p_per_fold[[v]]
slope_folds[v] <- c(coef(glm(data$y ~ log(ppf/(1-ppf)),family="binomial"))[2])
intercept_folds[v] <- coef(glm(data$y ~ offset(log(ppf/(1-ppf))),family="binomial"))
R2_folds[v] <- pseudo_Rsqrs(p = ppf, y = data$y)
calout <- loess(y ~ log(ppf/(1-ppf)), data = data)
#calout <- .obtain_calout(data = df[unlist(foldsb[[i]]),], modelmatrix = iv_matrix[[i]], coefs = coefs[,i])
eci_folds[v] <- (mean((ppf-fitted(calout))*(ppf-fitted(calout))))*(100)
}
## AUC
auc_results <- as.vector(unlist(ci.cvAUC(predictions=p, labels=df$y, folds=foldsb, confidence=0.95)))[-5]
names(auc_results) <- c(paste0("AUC_mean_", V, "fcv" ), paste0("AUC_se_", V, "fcv"), paste0("AUC_ci_lower_", V, "fcv"), paste0("AUC_ci_upper_", V, "fcv"))
## Get mean and standard error over all other results and store in a single vector:
## Calibration
intercept <- c(mean(intercept_folds), (sd(intercept_folds)/(sqrt(V) - 1)))
names(intercept) <- c(paste0("calib_int_mean_", V, "fcv" ), paste0("calib_int_se_", V, "fcv"))
slope <-  c(mean(slope_folds), (sd(slope_folds)/(sqrt(V) - 1)))
names(slope) <- c(paste0("calib_slope_mean_", V, "fcv" ), paste0("calib_slope_se_", V, "fcv"))
## R2 cox snell
R2 <- c(mean(R2_folds), (sd(R2_folds)/(sqrt(V) - 1)))
names(R2) <- c(paste0("R2_mean_", V, "fcv" ), paste0("R2_se_", V, "fcv"))
## ECI
eci <- c(mean(eci_folds), (sd(eci_folds)/(sqrt(V) - 1)))
names(eci) <- c(paste0("eci_mean_", V, "fcv" ), paste0("eci_se_", V, "fcv"))
results <- c(auc_results, intercept, slope, R2, eci)
results
get_cv_results <- function(scenario, df, V) {
results_cv <- list() #object to store results
for (i in 1:length(df)) {
print(i)
model <- s1[i, ]$model
results_cv[[i]] <- get_cv_estimands(df = df[[i]], model = model, V = V)
}
names(results_cv) <- c(1:length(df))
return(results_cv)
}
#### Load data #####
data_files <- list.files(path = scenario_1_data, recursive = T, full.names = F)
df <- lapply(paste0(scenario_1_data,data_files),readRDS,.GlobalEnv)
names(df) <- data_files
s1 <- read_rds(paste0(scenario_1_settings,"s1.Rds"))
## Obtain apparent performance results ##
system.time(results_app <- get_app_results(scenario = s1, df = df))
## Obtain cross validation results ##
system.time(results_10_cv <- get_cv_results(scenario = s1, df = df, V = 10))
df <- df[[9]]
model <- s1[9,]$model
####################
## Splitting data ##
####################
.cvFoldsB <- function(Y, V) {  #Create Balanced CV folds (stratify by outcome)
Y0 <- split(sample(which(Y=="0")), rep(1:V, length=length(which(Y==0))))
Y1 <- split(sample(which(Y=="1")), rep(1:V, length=length(which(Y==1))))
folds <- vector("list", length=V)
for (v in seq(V)) {folds[[v]] <- c(Y0[[v]], Y1[[v]])}
return(folds)
}
foldsb <- .cvFoldsB(Y = df$y, V = V)
#################################################
## Getting predictions depending on model used ##
#################################################
.doFit <- function(V, folds, model){  #Train/test glm for each fold
if (model == "OLS") {
fit <- glm(y~., data=df[-foldsb[[V]],], family=binomial) #%>%
#step(direction = "backward", trace = F) # This should be changeable depending on which thing you're using
iv_matrix <- model.matrix(object = fit$formula, data = df[foldsb[[V]],])
p <- predict(fit, newdata=df[foldsb[[V]],], type = "response")
} else { # If model = Firth (or svm for now)
fit <- logistf(y ~ ., data = df[-foldsb[[V]],], flic = T)
iv_matrix <- model.matrix(object = fit$formula, data = df[foldsb[[V]],]) #iv matrix of test fold
p <- 1 / (1 + exp(-iv_matrix %*% fit$coefficients))
}
coefs <- coef(fit)
results <- list(p, coefs, iv_matrix)
}
results <- (lapply(seq(V), .doFit, folds = foldsb, model = model))
p <- unlist(sapply(results, "[[", 1)) # Get out pred values as a single thing
p[unlist(foldsb)] <- p #Re-order pred values
View(s1)
p <- unlist(sapply(results, "[[", 1)) # Get out pred values as a single thing
p[unlist(foldsb)] <- p #Re-order pred values
p <- unlist(sapply(results, "[[", 1)) # Get out pred values as a single thing
p[unlist(foldsb)] <- p #Re-order pred values
p_per_fold <- sapply(results, "[[", 1) # getting the predictions per fold
####################
## Splitting data ##
####################
.cvFoldsB <- function(Y, V) {  #Create Balanced CV folds (stratify by outcome)
Y0 <- split(sample(which(Y=="0")), rep(1:V, length=length(which(Y==0))))
Y1 <- split(sample(which(Y=="1")), rep(1:V, length=length(which(Y==1))))
folds <- vector("list", length=V)
for (v in seq(V)) {folds[[v]] <- c(Y0[[v]], Y1[[v]])}
return(folds)
}
foldsb <- .cvFoldsB(Y = df$y, V = V)
#################################################
## Getting predictions depending on model used ##
#################################################
.doFit <- function(V, folds, model){  #Train/test glm for each fold
if (model == "OLS") {
fit <- glm(y~., data=df[-foldsb[[V]],], family=binomial) #%>%
#step(direction = "backward", trace = F) # This should be changeable depending on which thing you're using
iv_matrix <- model.matrix(object = fit$formula, data = df[foldsb[[V]],])
p <- predict(fit, newdata=df[foldsb[[V]],], type = "response")
} else { # If model = Firth (or svm for now)
fit <- logistf(y ~ ., data = df[-foldsb[[V]],], flic = T)
iv_matrix <- model.matrix(object = fit$formula, data = df[foldsb[[V]],]) #iv matrix of test fold
p <- 1 / (1 + exp(-iv_matrix %*% fit$coefficients))
}
coefs <- coef(fit)
results <- list(p, coefs, iv_matrix)
}
results <- (lapply(seq(V), .doFit, folds = foldsb, model = model))
p <- unlist(sapply(results, "[[", 1)) # Get out pred values as a single thing
p[unlist(foldsb)] <- p #Re-order pred values
p_per_fold <- sapply(results, "[[", 1) # getting the predictions per fold
coefs <- (sapply(results, "[[", 2)) # Get out model coefficients
iv_matrix <- (sapply(results, "[[", 3)) # get out the test matrices
#### Load data #####
data_files <- list.files(path = scenario_1_data, recursive = T, full.names = F)
df <- lapply(paste0(scenario_1_data,data_files),readRDS,.GlobalEnv)
names(df) <- data_files
df <- df[[1]]
mode; <- s1[1,]$model
model <- s1[1,]$model
####################
## Splitting data ##
####################
.cvFoldsB <- function(Y, V) {  #Create Balanced CV folds (stratify by outcome)
Y0 <- split(sample(which(Y=="0")), rep(1:V, length=length(which(Y==0))))
Y1 <- split(sample(which(Y=="1")), rep(1:V, length=length(which(Y==1))))
folds <- vector("list", length=V)
for (v in seq(V)) {folds[[v]] <- c(Y0[[v]], Y1[[v]])}
return(folds)
}
foldsb <- .cvFoldsB(Y = df$y, V = V)
#################################################
## Getting predictions depending on model used ##
#################################################
.doFit <- function(V, folds, model){  #Train/test glm for each fold
if (model == "OLS") {
fit <- glm(y~., data=df[-foldsb[[V]],], family=binomial) #%>%
#step(direction = "backward", trace = F) # This should be changeable depending on which thing you're using
iv_matrix <- model.matrix(object = fit$formula, data = df[foldsb[[V]],])
p <- predict(fit, newdata=df[foldsb[[V]],], type = "response")
} else { # If model = Firth (or svm for now)
fit <- logistf(y ~ ., data = df[-foldsb[[V]],], flic = T)
iv_matrix <- model.matrix(object = fit$formula, data = df[foldsb[[V]],]) #iv matrix of test fold
p <- 1 / (1 + exp(-iv_matrix %*% fit$coefficients))
}
coefs <- coef(fit)
results <- list(p, coefs, iv_matrix)
}
results <- (lapply(seq(V), .doFit, folds = foldsb, model = model))
p <- unlist(sapply(results, "[[", 1)) # Get out pred values as a single thing
p[unlist(foldsb)] <- p #Re-order pred values
p_per_fold <- sapply(results, "[[", 1) # getting the predictions per fold
coefs <- (sapply(results, "[[", 2)) # Get out model coefficients
iv_matrix <- (sapply(results, "[[", 3)) # get out the test matrices
df <- lapply(paste0(scenario_1_data,data_files),readRDS,.GlobalEnv)
names(df) <- data_files
s1 <- read_rds(paste0(scenario_1_settings,"s1.Rds"))
df <- df[[9]]
model <- s1[9,]$model
####################
## Splitting data ##
####################
.cvFoldsB <- function(Y, V) {  #Create Balanced CV folds (stratify by outcome)
Y0 <- split(sample(which(Y=="0")), rep(1:V, length=length(which(Y==0))))
Y1 <- split(sample(which(Y=="1")), rep(1:V, length=length(which(Y==1))))
folds <- vector("list", length=V)
for (v in seq(V)) {folds[[v]] <- c(Y0[[v]], Y1[[v]])}
return(folds)
}
foldsb <- .cvFoldsB(Y = df$y, V = V)
#################################################
## Getting predictions depending on model used ##
#################################################
.doFit <- function(V, folds, model){  #Train/test glm for each fold
if (model == "OLS") {
fit <- glm(y~., data=df[-foldsb[[V]],], family=binomial) #%>%
#step(direction = "backward", trace = F) # This should be changeable depending on which thing you're using
iv_matrix <- model.matrix(object = fit$formula, data = df[foldsb[[V]],])
p <- predict(fit, newdata=df[foldsb[[V]],], type = "response")
} else { # If model = Firth (or svm for now)
fit <- logistf(y ~ ., data = df[-foldsb[[V]],], flic = T)
iv_matrix <- model.matrix(object = fit$formula, data = df[foldsb[[V]],]) #iv matrix of test fold
p <- 1 / (1 + exp(-iv_matrix %*% fit$coefficients))
}
coefs <- coef(fit)
results <- list(p, coefs, iv_matrix)
}
results <- (lapply(seq(V), .doFit, folds = foldsb, model = model))
p <- unlist(sapply(results, "[[", 1)) # Get out pred values as a single thing
p[unlist(foldsb)] <- p #Re-order pred values
results <- (lapply(seq(V), .doFit, folds = foldsb, model = model))
View(results)
p <- unlist(sapply(results, "[[", 1)) # Get out pred values as a single thing
results <- (lapply(seq(V), .doFit, folds = foldsb, model = model))
unlist(sapply(results, "[[", 1))
p <- c(unlist(sapply(results, "[[", 1))) # Get out pred values as a single thing
p[unlist(foldsb)] <- p #Re-order pred values
p <- c(unlist(sapply(results, "[[", 1))) # Get out pred values as a single thing
p[unlist(foldsb)] <- p #Re-order pred values
p_per_fold <- sapply(results, "[[", 1) # getting the predictions per fold
coefs <- (sapply(results, "[[", 2)) # Get out model coefficients
iv_matrix <- (sapply(results, "[[", 3)) # get out the test matrices
## Obtain estimands ##
## for ECI
# .obtain_calout <- function(data, modelmatrix, coefs){
#   phat <- 1/(1+exp(-(modelmatrix%*%coefs)))
#   calout <- loess(data$y ~ log(phat/(1-phat)), data = data)
#   return(calout)
# }
#
## Empty objects to store results
slope_folds <- c()
intercept_folds <- c()
R2_folds <- c()
eci_folds <- c()
# For each fold, calculate calibration intercept & slope, R2 and ECI
for (v in 1:V){
# for easy reference
data <- df[unlist(foldsb[[v]]),]
ppf <- p_per_fold[[v]]
slope_folds[v] <- c(coef(glm(data$y ~ log(ppf/(1-ppf)),family="binomial"))[2])
intercept_folds[v] <- coef(glm(data$y ~ offset(log(ppf/(1-ppf))),family="binomial"))
R2_folds[v] <- pseudo_Rsqrs(p = ppf, y = data$y)
calout <- loess(y ~ log(ppf/(1-ppf)), data = data)
#calout <- .obtain_calout(data = df[unlist(foldsb[[i]]),], modelmatrix = iv_matrix[[i]], coefs = coefs[,i])
eci_folds[v] <- (mean((ppf-fitted(calout))*(ppf-fitted(calout))))*(100)
}
ppf <- p_per_fold[[v]]
p_per_fold <- sapply(results, "[[", 1) # getting the predictions per fold
coefs <- (sapply(results, "[[", 2)) # Get out model coefficients
iv_matrix <- (sapply(results, "[[", 3)) # get out the test matrices
p_per_fold <- as.list(sapply(results, "[[", 1)) # getting the predictions per fold
p_per_fold <- as.matrix(sapply(results, "[[", 1)) # getting the predictions per fold
iv_matrix <- list(sapply(results, "[[", 3)) # get out the test matrices
iv_matrix <- lapply(results, "[[", 3) # get out the test matrices
p_per_fold <- lapply(results, "[[", 1) # getting the predictions per fold
results <- (lapply(seq(V), .doFit, folds = foldsb, model = model))
p <- c(unlist(sapply(results, "[[", 1))) # Get out pred values as a single thing
p[unlist(foldsb)] <- p #Re-order pred values
p_per_fold <- lapply(results, "[[", 1) # getting the predictions per fold
coefs <- (sapply(results, "[[", 2)) # Get out model coefficients
iv_matrix <- lapply(results, "[[", 3) # get out the test matrices
## Obtain estimands ##
## for ECI
# .obtain_calout <- function(data, modelmatrix, coefs){
#   phat <- 1/(1+exp(-(modelmatrix%*%coefs)))
#   calout <- loess(data$y ~ log(phat/(1-phat)), data = data)
#   return(calout)
# }
#
## Empty objects to store results
slope_folds <- c()
intercept_folds <- c()
R2_folds <- c()
eci_folds <- c()
# For each fold, calculate calibration intercept & slope, R2 and ECI
for (v in 1:V){
# for easy reference
data <- df[unlist(foldsb[[v]]),]
ppf <- p_per_fold[[v]]
slope_folds[v] <- c(coef(glm(data$y ~ log(ppf/(1-ppf)),family="binomial"))[2])
intercept_folds[v] <- coef(glm(data$y ~ offset(log(ppf/(1-ppf))),family="binomial"))
R2_folds[v] <- pseudo_Rsqrs(p = ppf, y = data$y)
calout <- loess(y ~ log(ppf/(1-ppf)), data = data)
#calout <- .obtain_calout(data = df[unlist(foldsb[[i]]),], modelmatrix = iv_matrix[[i]], coefs = coefs[,i])
eci_folds[v] <- (mean((ppf-fitted(calout))*(ppf-fitted(calout))))*(100)
}
## AUC
auc_results <- as.vector(unlist(ci.cvAUC(predictions=p, labels=df$y, folds=foldsb, confidence=0.95)))[-5]
names(auc_results) <- c(paste0("AUC_mean_", V, "fcv" ), paste0("AUC_se_", V, "fcv"), paste0("AUC_ci_lower_", V, "fcv"), paste0("AUC_ci_upper_", V, "fcv"))
## Get mean and standard error over all other results and store in a single vector:
## Calibration
intercept <- c(mean(intercept_folds), (sd(intercept_folds)/(sqrt(V) - 1)))
names(intercept) <- c(paste0("calib_int_mean_", V, "fcv" ), paste0("calib_int_se_", V, "fcv"))
slope <-  c(mean(slope_folds), (sd(slope_folds)/(sqrt(V) - 1)))
names(slope) <- c(paste0("calib_slope_mean_", V, "fcv" ), paste0("calib_slope_se_", V, "fcv"))
## R2 cox snell
R2 <- c(mean(R2_folds), (sd(R2_folds)/(sqrt(V) - 1)))
names(R2) <- c(paste0("R2_mean_", V, "fcv" ), paste0("R2_se_", V, "fcv"))
## ECI
eci <- c(mean(eci_folds), (sd(eci_folds)/(sqrt(V) - 1)))
names(eci) <- c(paste0("eci_mean_", V, "fcv" ), paste0("eci_se_", V, "fcv"))
results <- c(auc_results, intercept, slope, R2, eci)
results
df <- lapply(paste0(scenario_1_data,data_files),readRDS,.GlobalEnv)
names(df) <- data_files
s1 <- read_rds(paste0(scenario_1_settings,"s1.Rds"))
## Obtain apparent performance results ##
system.time(results_app <- get_app_results(scenario = s1, df = df))
## Obtain cross validation results ##
system.time(results_10_cv <- get_cv_results(scenario = s1, df = df, V = 10))
source("scripts/estimand functions.R")
## Obtain cross validation results ##
system.time(results_10_cv <- get_cv_results(scenario = s1, df = df, V = 10))
View(results_10_cv)
system.time(results_5_cv <- get_cv_results(scenario = s1, df = df, V = 5)
system.time(results_5_cv <- get_cv_results(scenario = s1, df = df, V = 5))
##################################
##################################
##################################
## get estimands 1 scenario:
set.seed(123)
############ Load necessary stuff ############
source("scripts/setup.R")
source("scripts/libraries.R")
source("scripts/estimand functions.R")
#### Load data #####
data_files <- list.files(path = scenario_1_data, recursive = T, full.names = F)
df <- lapply(paste0(scenario_1_data,data_files),readRDS,.GlobalEnv)
names(df) <- data_files
s1 <- read_rds(paste0(scenario_1_settings,"s1.Rds"))
## Obtain apparent performance results ##
system.time(results_app <- get_app_results(scenario = s1, df = df))
## Obtain cross validation results ##
system.time(results_10_cv <- get_cv_results(scenario = s1, df = df, V = 10))
system.time(results_5_cv <- get_cv_results(scenario = s1, df = df, V = 5))
#### Load simulation data #####
data_files <- list.files(path = scenario_1_validation_data, recursive = T, full.names = F)
val_df <- lapply(paste0(scenario_1_validation_data,val_data_files),readRDS,.GlobalEnv)
#### Load validation data #####
val_data_files <- list.files(path = scenario_1_validation_data, recursive = T, full.names = F)
val_df <- lapply(paste0(scenario_1_validation_data,val_data_files),readRDS,.GlobalEnv)
names(val_df) <- val_data_files
?set.seed
state <- runif(n_sim, 0, 10000)
# Store seed values
n_sim <- 100 # how many repetitions?
state <- runif(n_sim, 0, 10000)
set.seed(123)
# Store seed values
n_sim <- 100 # how many repetitions?
state <- runif(n_sim, 0, 10000)
set.seed(123)
# Store seed values
n_sim <- 100 # how many repetitions?
state <- runif(n_sim, 0, 10000)
set.seed(123)
# Store seed values
n_sim <- 2 # how many repetitions?
state <- runif(n_sim, 0, 10000)
## Libraries, file paths and functions
source("scripts/setup.R")
source("scripts/estimand functions.R")
## Load validation data
val_data_files <- list.files(path = scenario_1_validation_data, recursive = T, full.names = F)
val_df <- lapply(paste0(scenario_1_validation_data,val_data_files),readRDS,.GlobalEnv)
names(val_df) <- val_data_files
## Load scenario settings
s1 <- read_rds(paste0(scenario_1_settings,"s1.Rds"))
# Reproduction seed
set.seed(123)
# Store seed values
n_sim <- 2 # how many iterations?
state <- runif(n_sim, 0, 10000)
for (i in 1:4){
scenario_specific <- paste0("scenario", i, "/")
dir.create(file.path(paste0("Output/", scenario_specific)), recursive = TRUE)
}
for (i in 1:4){
scenario_specific <- paste0("scenario ", i, "/")
dir.create(file.path(paste0("Output/", scenario_specific)), recursive = TRUE)
}
s1_output <- "Output/scenario 1/"
# Reproduction seed
set.seed(123)
data_files <- list.files(path = scenario_1_data, recursive = T, full.names = F)
df <- lapply(paste0(scenario_1_data,data_files),readRDS,.GlobalEnv)
names(df) <- data_files
## Obtain apparent estimands
system.time(results_app <- get_app_results(scenario = s1, df = df))
## Obtain internal validation estimands
system.time(results_10_cv <- get_cv_results(scenario = s1, df = df, V = 10))
system.time(results_5_cv <- get_cv_results(scenario = s1, df = df, V = 5))
## Make a vector of all results + state
test <- list(results_app, results_10_cv, results_5_cv))
## Make a vector of all results + state
test <- list(results_app, results_10_cv, results_5_cv)
test1 <- lapply(test, "[[[[", 1)
test1 <- lapply(test, "[[", 1)
View(test1)
test1 <- unlist(lapply(test, "[[", 1))
View(test1)
i <- 1
assign(paste0("s1_", i), unlist(lapply(results_lists, "[[", i)))
results_lists <- list(results_app, results_10_cv, results_5_cv)
assign(paste0("s1_", i), unlist(lapply(results_lists, "[[", i)))
assign(paste0("s1_results", i), c("seed_state" = state[i], unlist(lapply(results_lists, "[[", i))))
# Reproduction seed
set.seed(123)
# Store seed values
n_sim <- 2 # how many iterations?
state <- runif(n_sim, 0, 10000)
for(j in 1:n_sim){
set.seed(state[j])
## Create and load simulation data
source("scripts/data generation scenario 1.R")
data_files <- list.files(path = scenario_1_data, recursive = T, full.names = F)
df <- lapply(paste0(scenario_1_data,data_files),readRDS,.GlobalEnv)
names(df) <- data_files
## Obtain apparent estimands
system.time(results_app <- get_app_results(scenario = s1, df = df))
## Obtain internal validation estimands
system.time(results_10_cv <- get_cv_results(scenario = s1, df = df, V = 10))
system.time(results_5_cv <- get_cv_results(scenario = s1, df = df, V = 5))
## Make a vector of all results + state
for(i in 1:length(results_app)){
results_lists <- list(results_app, results_10_cv, results_5_cv)
saveRDS(assign(paste0("s1_results", i), c("seed_state" = state[i], unlist(lapply(results_lists, "[[", i)))),
file = paste0(s1_output, "s1_", i,"_", state[i],".Rds"))
}
}
for(j in 1:n_sim){
set.seed(state[j])
## Create and load simulation data
source("scripts/data generation scenario 1.R")
data_files <- list.files(path = scenario_1_data, recursive = T, full.names = F)
df <- lapply(paste0(scenario_1_data,data_files),readRDS,.GlobalEnv)
names(df) <- data_files
## Obtain apparent estimands
system.time(results_app <- get_app_results(scenario = s1, df = df))
## Obtain internal validation estimands
system.time(results_10_cv <- get_cv_results(scenario = s1, df = df, V = 10))
system.time(results_5_cv <- get_cv_results(scenario = s1, df = df, V = 5))
## Make a vector of all results + state
for(i in 1:length(results_app)){
results_lists <- list(results_app, results_10_cv, results_5_cv)
saveRDS(assign(paste0("s1_results", i), c("seed_state" = state[j], unlist(lapply(results_lists, "[[", i)))),
file = paste0(s1_output, "s1_", i,"_", state[i],".Rds"))
}
}
# Reproduction seed
set.seed(123)
# Store seed values
n_sim <- 2 # how many iterations?
state <- floor(runif(n_sim, 0, 10000))
for(j in 1:n_sim){
set.seed(state[j])
## Create and load simulation data
source("scripts/data generation scenario 1.R")
data_files <- list.files(path = scenario_1_data, recursive = T, full.names = F)
df <- lapply(paste0(scenario_1_data,data_files),readRDS,.GlobalEnv)
names(df) <- data_files
## Obtain apparent estimands
system.time(results_app <- get_app_results(scenario = s1, df = df))
## Obtain internal validation estimands
system.time(results_10_cv <- get_cv_results(scenario = s1, df = df, V = 10))
system.time(results_5_cv <- get_cv_results(scenario = s1, df = df, V = 5))
## Make a vector of all results + state
for(i in 1:length(results_app)){
results_lists <- list(results_app, results_10_cv, results_5_cv)
saveRDS(assign(paste0("s1_results", i), c("seed_state" = state[j], unlist(lapply(results_lists, "[[", i)))),
file = paste0(s1_output, "s1_", i,"_", state[i],".Rds"))
}
}
j <- 1
set.seed(state[j])
for(j in 1:n_sim){
set.seed(state[j])
## Create and load simulation data
source("scripts/data generation scenario 1.R")
data_files <- list.files(path = scenario_1_data, recursive = T, full.names = F)
df <- lapply(paste0(scenario_1_data,data_files),readRDS,.GlobalEnv)
names(df) <- data_files
## Obtain apparent estimands
system.time(results_app <- get_app_results(scenario = s1, df = df))
## Obtain internal validation estimands
system.time(results_10_cv <- get_cv_results(scenario = s1, df = df, V = 10))
system.time(results_5_cv <- get_cv_results(scenario = s1, df = df, V = 5))
## Make a vector of all results + state
for(i in 1:length(results_app)){
results_lists <- list(results_app, results_10_cv, results_5_cv)
saveRDS(assign(paste0("s1_results", i), c("seed_state" = state[j], unlist(lapply(results_lists, "[[", i)))),
file = paste0(s1_output, "s1_", i,"_", state[j],".Rds"))
}
}
# Reproduction seed
set.seed(123)
# Store seed values
n_sim <- 2 # how many iterations?
state <- floor(runif(n_sim, 0, 10000))
for(j in 1:n_sim){
set.seed(state[j])
## Create and load simulation data
source("scripts/data generation scenario 1.R")
data_files <- list.files(path = scenario_1_data, recursive = T, full.names = F)
df <- lapply(paste0(scenario_1_data,data_files),readRDS,.GlobalEnv)
names(df) <- data_files
## Obtain apparent estimands
system.time(results_app <- get_app_results(scenario = s1, df = df))
## Obtain internal validation estimands
system.time(results_10_cv <- get_cv_results(scenario = s1, df = df, V = 10))
system.time(results_5_cv <- get_cv_results(scenario = s1, df = df, V = 5))
## Make a vector of all results + state
for(i in 1:length(results_app)){
results_lists <- list(results_app, results_10_cv, results_5_cv)
saveRDS(assign(paste0("s1_results", i), c("seed_state" = state[j], unlist(lapply(results_lists, "[[", i)))),
file = paste0(s1_output, "s1_", i,"_", state[j],".Rds"))
}
}
